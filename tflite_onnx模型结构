# 任务
1. 了解onnx 和tflite 模型的中间结构 具体变化操作



# ONNX
## 介绍
	基于 ​Protobuf​（Protocol Buffers）序列化格式

## 目的
	将元数据(meta data)与图形(graph)相关联，图形包含所有可执行元素
	定义了可扩展的计算图模型，以及内置运算符和标准数据类型的定义 
  
 ## 模型组成  
    可扩展计算图模型的定义
    标准数据类型的定义
    内置运算符的定义
    
## 模型组成部分以及文件结构
内容包含：

	ModelProto（模型协议）： 定义整个神经网络模型的结构，包括模型的元数据、图结构以及其他相关信息。
	GraphProto（图协议）： 描述神经网络的计算图结构，包括节点（NodeProto）、边（连接节点的边）等信息。
	NodeProto（节点协议）： 用于定义计算图中的节点，每个节点表示一个操作或计算步骤，包括该节点的输入、输出、操作类型等信息。
	ValueInfoProto（值信息协议）： 用于描述计算图中的值（如张量）的信息，包括名称、数据类型、形状等。
	TensorProto（张量协议）： 用于描述神经网络中的张量，包括张量的数据、形状、数据类型等信息。
	AttributeProto（属性协议）： 用于表示节点或图的属性，这些属性可能包含操作的参数、超参数等信息。

结构包含：

	Model：表示整个ONNX模型，包含图结构和解析器格式、opset版本、导出程序类型等信息。
	Graph：表示图结构，是ONNX模型的主要组成部分，包含了模型中的所有节点以及节点之间的连接关系。 
		node：NodeProto类型，存放着模型中的所有计算节点。表示算子（如conv、relu、linear等），包含了算子的输入、输出、名称、类型以及属性等信息。
		input：ValueInfoProto类型，存放着模型所有的输入节点，包括图片输入节点和权重输入节点。
		output：ValueInfoProto类型，存放着模型所有的输出节点，包含了输入和输出的名称、形状和数据类型等信息。
		initializer：TensorProto类型，存放着模型所有的权重。

    
 ## ONNX Graph
1. 序列化图由一组**元数据字段(metadata)**，**模型参数列表(a list of model parameters)**和**计算节点列表组成(a list of computation nodes)**
2. 每个计算数据流图被构造为拓扑排序的节点列表，这些节点形成图形，其必须没有周期
3. 是模型中所有操作发生的地方

### NodeProto
NodeProto定义了每个操作（OP）的具体操作，一个节点代表一个操作

### TensorProto
用来保存权重（weights）和偏置（biases）等模型参数 ，存储在GraphProto的initialize

### ValueInfoProto
定义了输入输出形状信息和张量的维度信息

## 个人理解
https://zhuanlan.zhihu.com/p/597240062

模型文件的整体结构：

---
ModelProto
├── ir_version            # 中间表示（IR）版本（如 8）
├── opset_import          # 依赖的操作符集（如 ai.onnx v15）
├── producer_name         # 生成模型的框架（如 PyTorch）
├── producer_version      # 框架版本（如 1.10）
├── ***graph: GraphProto***     # 核心计算图（包含所有计算逻辑）
└── metadata_props        # 元数据（如作者、描述）

---	

计算图（GraphProto）的结构：

---
GraphProto
├── node: [NodeProto]     # 计算节点列表（如卷积、激活函数）
├── input: [ValueInfoProto]  # 输入张量描述
├── output: [ValueInfoProto] # 输出张量描述
├── initializer: [TensorProto]  # 权重/常量数据（如卷积核）
└── value_info: [ValueInfoProto] # 中间张量描述（可选，用于调试）

---

每个节点对应一个运算符（如Conv、ReLU）



## 二进制文件结构
	Protobuf使用一种紧凑的二进制格式，每个字段都有特定的tag和类型，然后是数据
	ONNX模型由多个嵌套的Protobuf消息构成（见昨日笔记）
	要获取ONNX模型中每个节点（NodeProto）在原始文件中的内存地址（偏移量）和占用大小
	字段地址 = Tag字节 + Length字节 + Data字节

## 利用Python获得结论
	参数结构所占的模型大小占比百分之95以上
	元数据和结构占比较小


## ONNX模型实例

---

ir_version: 8
opset_import { domain: "ai.onnx", version: 15 }
producer_name: "pytorch"
graph {
  input { name: "input", type { tensor_type { elem_type: 1, shape { dim { dim_value: 1 }, dim { dim_value: 3 }, dim { dim_value: 224 }, dim { dim_value: 224 } } } } }
  output { name: "output", type { tensor_type { elem_type: 1 } } }
  initializer { name: "conv_weight", dims: [64,3,3,3], data_type: 1, raw_data: "..." }
  node {
    op_type: "Conv",
    input: "input",
    input: "conv_weight",
    output: "conv_output",
    attribute { name: "strides", ints: [2,2] },
    attribute { name: "pads", ints: [1,1,1,1] }
  }
  node {
    op_type: "Relu",
    input: "conv_output",
    output: "output"
  }
}

--- 



## ONNX 模型拆分并合并
官方网址：
	https://onnx.ai/onnx/api/compose.html
	https://onnx.ai/onnx/api/utils.html
	https://github.com/ThanatosShinji/onnx-tool/blob/main/data/GraphFusion.md

### 过程中遇到的问题
1. 拆分得到的子模型： 输入张量 输出张量 计算节点 形状信息 元数据 初始化器 ， 也可独立运行输出
2. 模型拆分再重合的过程中，两个模型内部存在同名的节点、张量或 value_info（例如 conv_blob1），导致合并时名称冲突。于是需要重新命名




   	
# Tflite
## Tflite介绍
	TFLite 模型是基于 ​FlatBuffers​（一种高效的序列化格式）的二进制文件,核心文件定义在schema.fbs文件中
	TFLite模型文件格式：主结构体是Modle，其中的operator_codes定义了该模型用到的算子Op Code;
	subgraphs定义了Model中的子图，其中第一个子图是主图；
	buffers:是数据存储区域，主要保存是模型的权重


## 文件结构
	TensorFlow Lite（TFLite）模型文件的结构基于 ​FlatBuffers​（一种高效的序列化库）
	无需解析即可直接访问数据（直接通过内存偏移量）（ONNX每个字段都有特定的tag和类型，然后是数据）

文件组成（schema.fbs:

--- 

** 子图**
**操作码表**
** 版本和签名**
**Buffers（缓冲区） ** （存储模型权重、常量数据的原始字节块）

---

## 文件内存情况
	Buffers 是 FlatBuffers 格式中存储模型二进制数据的核心组件。它们的主要作用是为模型中的 ​权重（weights）​、偏置（bias）​、量化参数 和其他 ​常量数据 提供存储空间
	TFLite首先会根据每个张量的大小(size)，为它们分配一个偏移地址(offset)，并且保证不会有任何一个张量的数据在错误的时间覆盖任何其他有用的张量
	# flatc -t --raw-binary schema.fbs -- /home/yang/Model_File/PixtalksModel/t2d_fd/fd_v1_22_20230802/fd_v1_22_20230802_quantize.tflite

--- 

## TFLite 模型结构示例(数据来源)
Model
└── Subgraph
    └── Tensors
        ├── Tensor1 → Buffer[3] (权重)
        ├── Tensor2 → Buffer[4] (偏置)
        └── Tensor3 → Buffer[0] (动态数据)
        
---


## 具体模型内容
	INT8 存储 + ​INT32 计算

## operator
	onnx的操作是relu和conv分开，在TFlite中是放在一起的
	张量后的Type=3​（UINT8）和Type=9​（INT8）表示张量是量化后的
	重要的是**算子列表**：每一层的输入输出信息存储在 ​SubGraph中的Operators里，每个Operator对象中的inputs和outputs字段标号了张量的下标
	
	
	

## 子图
1. tflite可能包含多个子图（通常有一个主图）
2. 子图包含：张量  操作符 输入输出张量索引
3. 除此之外可能还有name

## 操作码表
定义模型中所有操作符的类型（如 CONV_2D、FULLY_CONNECTED）及其版本（兼容性控制）

---
eg. 
enum BuiltinOperator : byte {
  ADD = 0,
  AVERAGE_POOL_2D = 1,
  CONCATENATION = 2,
  CONV_2D = 3,
  DEPTHWISE_CONV_2D = 4,
  // DEPTH_TO_SPACE = 5,
  // DEQUANTIZE = 6,
  EMBEDDING_LOOKUP = 7,

}

---

## 版本和签名
指定 TFLite 格式的版本等信息


## 个人理解
一个子图就好比一张纸 在纸之外有操作码表（类比操作符字典）之外有Buffers（类比“文件夹”中的“数据仓库”）
并且在子图中</br>
张量：定义子图中的所有tensor（定义了形状、类型和对应的buffer索引值）
Inputs/oupus： 通过索引的形式定义了整个图的输入、输出tensor
operators： 定义了子图中的各个算子
https://blog.csdn.net/u011279649/article/details/83186550 比较详细

---
Model
├── OperatorCodes          # 全局操作符类型列表（如 Conv2D、Add）
├── SubGraphs              # 子图列表
│   └── SubGraph 1
│       ├── Tensors        # 子图的张量列表
│       ├── Inputs         # 输入张量索引（如 [0]）
│       ├── Outputs        # 输出张量索引（如 [10]）
│       └── Operators     # 算子列表（通过 opcode_index 引用 OperatorCodes）
|———版本和描述
└── Buffers                # 全局权重/常量数据仓库

---

一个子图包含多个操作符


# ONNX 和 Tflite区别
| 特性               | ONNX                                      | TFLite                                  |
|--------------------|-------------------------------------------|-----------------------------------------|
| ​**序列化格式**​      | Protobuf（通用但略庞大）                  | FlatBuffers（高效紧凑）                 |
| ​**计算图结构**​      | 单一全局计算图（DAG）                     | 支持多个子图（SubGraph）                |
| ​**操作符定义**​      | 通过 `opset_import` 声明全局操作符集      | 每个子图引用模型级别的 OperatorCodes    |
| ​**权重存储**​        | 初始器（Initializers）与节点输入名称绑定  | 缓冲区（Buffers）通过张量索引引用       |
| ​**动态形状支持**​    | 支持动态维度（如 `dim_param`）            | 有限支持（需固定大部分维度）            |


# 模型调用
## 环境

## ONNX	
    使用onnxruntime.InferenceSession加载模型。
    获取输入名称和输出名称。
    将输入数据转换成numpy数组，符合输入形状和类型。
    运行sess.run()，得到输出。
    
## TFlite
    使用Interpreter加载模型文件。
    获取输入输出的详细信息，比如输入的形状和数据类型。
    可能需要调整输入数据的类型和形状，比如uint8还是float32。
    预处理图像，转换成模型需要的输入格式。
    调用interpreter.invoke()，然后获取输出张量。
    反量化
    相当于对于Tflite模型 对于输入数据要匹配类型 输出也要进行反量化
    
 ## 利用cmake编译




# 卷积算计

## 基本的卷积运算
两者的卷积运算都支持相同的核心参数，包括卷积核大小（kernel size）、步长（stride）、填充（padding）、膨胀率（dilation）、分组数（groups）
1. 通过卷积核在输入数据（如图像）上按步长（stride）滑动，逐位置计算局部区域的加权和。
2. 输出特征图的每个值都是输入局部区域与卷积核的逐元素乘积之和（加上可选的偏置项）
3. 基本的参数有：卷积核尺寸，步长，padding，膨胀率，分组数
4. 卷积基本的填充方式:
		无填充：输出尺寸=⌊输入尺寸−卷积核尺寸+1​⌋/步长
		Same Padding（保持输出尺寸：输出尺寸=⌈输入尺寸/步长​⌉
		全填充：填充至卷积核能覆盖输入的所有可能位置，输出尺寸大于输入尺寸。 输出尺寸=『输入尺寸+卷积核尺寸−1​』/步长



## ONNX与TFlite卷积运算区别
| ​**分类**               | ​**TensorFlow Lite (TFLite)**                                                                 | ​**ONNX**                                                                                     | ​**注意事项**                                                                 |
|-------------------------|---------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| ​**填充计算方式**        | 支持 `SAME`（动态计算填充量）和 `VALID`（无填充）。                                           | 通过 `AutoPad` 属性指定：`SAME_UPPER`、`SAME_LOWER`、`VALID` 等。                           | 输入尺寸为奇数时，`SAME` 填充可能导致输出尺寸差异。                          |
| ​**数据格式**            | 默认使用 ​**NHWC**​（Batch, Height, Width, Channels）。                                       | 默认使用 ​**NCHW**​（Batch, Channels, Height, Width）。                                       | 模型转换时需显式处理格式转换（如通过转置操作）。                            |
| ​**激活函数融合**        | 支持与 ReLU、ReLU6 等激活函数融合为单一算子。                                                 | 激活函数通常为独立算子（如 `Relu`），依赖运行时优化实现融合。                               | 融合操作影响性能但不影响数学结果。                                          |
| ​**量化实现**            | 支持全整型量化（int8）、float16 等，依赖硬件加速器特性。                                      | 通过 `QuantizeLinear`/`DequantizeLinear` 算子实现量化，支持动态/静态量化。                   | 不同框架的量化参数（如零点、缩放因子）需对齐，否则结果不一致。              |
| ​**权重顺序**            | 卷积核权重形状为 `[H, W, InChannels, OutChannels]`（NHWC 格式）。                            | 卷积核权重形状为 `[OutChannels, InChannels, H, W]`（NCHW 格式）。                           | 转换模型时需转置权重顺序。                                                  |
| ​**膨胀卷积支持**        | 明确支持 `dilation` 参数，但部分旧版本移动端运行时可能有限制。                                | 通过 `dilations` 属性支持，需确保运行时支持。                                               | 验证目标设备/运行时的膨胀卷积兼容性。                                       |
| ​**分组卷积**            | 通过 `groups` 参数支持分组卷积（如深度可分离卷积）。                                          | 同样支持 `group` 参数，但需确保输入/输出通道数能被 `group` 整除。                           | 分组数不匹配会导致模型转换失败。                                            |
| ​**部署优化**            | 针对移动端/嵌入式设备优化，支持算子融合、内存重用等。                                          | 依赖运行时实现优化（如 ONNX Runtime 的图优化）。                                             | ONNX 的优化程度取决于具体运行时（如 ONNX Runtime vs. TensorRT）。          |
| ​**动态输入尺寸支持**    | 支持动态输入尺寸，但可能影响性能（需预分配内存）。                                             | 支持动态尺寸（通过 `None` 或符号维度），但部分运行时要求固定输入尺寸。                      | 部署前需测试目标平台对动态尺寸的支持。                                      |







