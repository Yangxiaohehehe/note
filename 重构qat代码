# 任务介绍
需要将原先的qat代码进行重构

官方api
https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide?hl=zh-cn


具体任务包含了:

插一个优先级不高的任务，重构qat训练代码：
1.目前export_qat.py里是调用了/media/data2/pixtalks_public/tflite_training里的内容，需将其简化为一个单独无依赖其余项目的脚本
2.训练的一些配置参数写到配置文件(yaml)里
4.看每个epoch结束是否能加进测试代码


待做：
3.现做法是将representative_dataset数据一次加载到内存里，应该是显存占用大的原因，将其改为训练时按需加载(train_distill.py中有生成label的参考)
4. batch问题 不再是固定尺寸1




～～解决～～：
保存模型：调用test的代码进行测试



最主要需要整理的部分是有关dataset的部分。


## 总结
~~1. 训练配置yaml文件的构建~~
2. 一些函数的整理
3. 数据修改,包括读取数据和batch问题
4. 每个epoch加入测试代码




# 理解原代码
原先ONNX2tflite函数

## 流程
​​1. 模型转换​​
将输入的ONNX模型转换为Keras模型，再进一步转换为TFLite格式，支持浮点或量化模型生成。
​​
2. 量化支持​​
​​量化感知训练（QAT）​​：在训练过程中模拟量化误差，微调模型权重以提升量化后的精度。
​​后训练量化（PTQ）​​：通过校准数据静态确定量化参数，减少模型大小并加速推理。
​​全整型量化​​：支持将输入/输出设置为int8或uint8类型。
​​
新理解：
1. 完成一些配置（包括onnx模型转换、编译等）
2. 配置数据集 数据集的标签是通过源模型产生的label，而不是原label，因为目标是降低量化产生的误差而不是优化。



## 参数解析
基础配置​​：随机种子、GPU内存限制、输入/输出数据类型（int8/uint8）等。
​​QAT配置​​：学习率、训练数据路径、批次大小、验证集比例、训练轮数等。
​​PTQ配置​​：校准数据路径、校准数据量限制、输入形状等。


## QAT量化具体
### 层选择量化：
	apply_quantization函数，根据layer_quant参数选择需要量化的层（例如，仅量化后半部分层），
过程中具体使用了quantization.keras.quantize_annotate_layer函数，这个函数可以标注哪一层需要量化

在量化过程中：
	因为尝试“量化某些层”以跳过量化对准确率影响最大的层。
	与从头开始训练相比，使用量化感知训练进行微调的效果一般更好。
​​不过这个选择了全部量化

之后就利用了clone_model和quantize_apply生成带量化注释的Keras模型。

然后具体应用了量化标注​
底层逻辑：
插入伪量化节点（FakeQuant nodes），模拟推理时的量化误差（如权重/激活值的8位舍入）。
修改模型结构，但保持浮点权重（训练时仍用浮点计算，但模拟量化效果）。
	

### 模型编译阶段：
配置：
​​优化器​​：
	使用 Adam 优化器，学习率为 lr。
	参数 beta_1=0.9（一阶矩衰减率）、beta_2=0.999（二阶矩衰减率）、epsilon=1e-7（数值稳定项）。
	
​​损失函数​​：
	mean_squared_error（均方误差）：适用于回归任务（如特征嵌入匹配）。
	
​​评估指标​​：
	cosine_similarity（余弦相似度）：衡量特征向量的方向一致性，常用于人脸识别/特征比对任务。


编译后利用：
q_aware_model.summary()
打印量化后的模型结构，验证量化层是否按预期插入（如 QuantizeLayer 相关层）。
以及检查参数量变化（量化后部分层参数可能减少，但训练时仍为浮点权重）。


### 数据加载阶段：
​​数据加载​​：根据data_iter类型生成训练/验证数据集，支持从ONNX模型生成标签（用于特征对齐）。



​​训练与保存​​：执行模型训练，生成包含量化信息的TFLite模型（文件名含_qat后缀）。


### 量化感知训练
q_aware_model.fit
然后将训练好的量化感知模型转换为 TFLite 格式，并应用量化优化。


## 数据预处理




## 问题


## 待处理

1. 数据集的dataloader处理
（1） 蒸馏的中的处理
（2） 模型本身推倒的处理 
























