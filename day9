# 任务
1. 继续训练 见昨日笔记
2. 1206部分先测试计算量，然后利用1123的配置重新跑一次看看结果，
3. 合并人脸和手掌的训练代码
4.虹膜识别 ：数据集（规模 ） 方法  产品



# 虹膜识别

## 数据集
| 数据库名称                  | 规模                                                                 | 描述                                                                                                 | 网址                                                                                                   | 使用情况                                                                 |
|-----------------------------|----------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 中国科学院虹膜图像数据库（CASIA-Iris） | 54,607张图像（1,800+真实受试者，1,000虚拟受试者）                     | 8位灰度JPEG文件，近红外照明下收集或合成；含掌纹数据集                                                | [链接](http://english.ia.cas.cn/db/201610/t20161026_169399.html)                                      | 开放使用，需要注册账号社申请                                                                 |
| UTIRIS数据库                | 1,540张图像（79名受试者，158类）                                     | 包含可见波长（VW）和近红外（NIR）成像的虹膜数据                                                     | [链接](https://www.dropbox.com/scl/fi/z36qfhyzqum9n3slwta4t/UTIRIS_V.1.zip?rlkey=9w2hkphjuhwe4lruc0yicu0r8&dl=0) | 开放使用，可直接下载                                                                 |
| 虹膜识别数据库地址           | 包含12个子数据集（可申请子数据集见描述）                             | 子数据集：<br>- Warsaw-BioBase-Disease-Iris v2.1（1793 NIR+1203彩色）<br>- Warsaw-BioBase-Smartphone-Iris v1.0（3192张）<br>- Warsaw-BioBase-Post-Mortem-Iris v3.0（1094 NIR+785可见光）<br>- Warsaw-BioBase-Pupil-Dynamics v3.0（166眼动态数据） | [链接](http://zbum.ia.pw.edu.pl/EN/node/46)                                                           | 需机构申请，仅限非商业研究                                               |
| MMU虹膜数据集               | 460张图像（46人，左/右眼各5张）                                      | 包含红外（IRIS）图像和空文件                                                                        | [链接](https://www.kaggle.com/datasets/naureenmohammad/mmu-iris-dataset)                              | 开源                                                                     |
| GI4E数据库                  | 1,339张图像（103个受试者，每人12张）                                 | 标准网络摄像头采集，含非虹膜干扰（如睫毛、镜框）                                                    | [主站](https://www.unavarra.es/gi4e/databases/gi4e/)<br>[Kaggle](https://www.kaggle.com/datasets/masurte/gi4e-gaze-interaction-for-everybody) | 仅限非商业科学用途                                                       |
| U2Eyes数据库                | 600万张合成双目图像                                                  | 分辨率3840x2160像素（4K），含皮肤纹理；需通过代码生成                                               | [代码库](https://github.com/benoit-bossavit/U2Eyes?tab=readme-ov-file)                                | 无法下载，需自行生成                                                     |
| UBIRIS.v2                   | 11,102张图像（261名受试者）                                          | 无约束条件（远距离、移动、可见波长）拍摄，含真实噪声因素                                            | 原网址无法访问                                                                                        | 已失效                                                                   |


## 方法

### Iris_Osiris_v4.1（基于Daugman 的经典方法）
介绍：开源项目“Iris_Osiris_v4.1”提供了一个基于C++和OpenCV的虹膜识别解决方案，适用于Linux系统。（开源工具包）
步骤：预处理->虹膜定位->特征提取->体征匹配->决策
	定位：霍夫变换（Hough Transform），用来检测图像中的圆形结构，定位外边界。内边界的定位可以依据瞳孔的大小、位置，通过简单的几何计算得出
	特征提取：使用Gabor滤波器->特征编码和压缩-
	特征匹配：常见的匹配算法有欧氏距离、马氏距离和相关系数等
		

### Wildes方法
介绍：强调通过图像配准（Image Registration）​对齐虹膜区域，并利用拉普拉斯金字塔提取多尺度纹理特征。
步骤同1：
	定位同1：
	特征提取：构建拉普拉斯金字塔​（多尺度分解），提取不同分辨率下的纹理特征，通过方向梯度直方图（HOG）​或局部二值模式（LBP）编码纹理。
	匹配：使用归一化相关系数（NCC）或欧氏距离衡量特征相似性
效果：

### 局部二值模式（LBP）​
介绍：将虹膜纹理分解为局部区域的灰度对比模式，生成统计直方图作为特征
步骤：预处理->LBP编码->直方图统计->匹配
	LBP编码：对每个像素邻域（如3×3）计算二值模式
	直方图统计：将虹膜图像分块，计算每块的LBP直方图并拼接为全局特征。
	匹配：使用卡方距离（Chi-Square）或直方图交集进行比对

### SIFT/SURF特征匹配
介绍：提取虹膜图像中的关键点​（如纹理拐点、高曲率区域），通过描述子（SIFT/SURF）进行匹配。
步骤：关键点检测->描述子生成->匹配
	关键点检测： SIFT：通过高斯差分（DoG）检测尺度空间极值点。SURF：利用Hessian矩阵近似加速检测。
	描述子生成：计算关键点周围区域的梯度方向直方图（SIFT）或Haar小波响应（SURF）
	匹配：使用最近邻搜索（如FLANN）或RANSAC剔除误匹配
	
### 深度学习方法DeepIrisNet2 （2019年）
介绍：需要经典的虹膜归一化步骤，也不需要非常精确的虹膜分割
步骤：基于双CNN的虹膜分割框架，第一阶段CNN检测虹膜和瞳孔边界盒（Yolo）—>第二阶段CNN将边界盒检测到的区域作为输入，进行语义像素分割，得到真实的虹膜区域->再经过网络DeepIrisNet2进行验证

#### 评估
评估标准：三个阶段分别评估（边界盒检测，语义分割，相似度得分）
		边界盒：工作特征(ROC)曲线下的面积(AUC)来计算准确性
		语义分割：(µ)均值和标准偏差(σ)精密§、recall ®和F-measure (F)指标
		相似得分：EER
效果：
	1.边界盒效果
	2.语义分割效果
	3.模型辨别效果（分为可见光和红外数据集测试）





### 深度学习方法IrisParseNet
介绍：完整的虹膜分割解决方案，将虹膜掩膜和参数化的虹膜内外边界主动建模为统一的多任务网络，共同实现虹膜面具和参数化的虹膜内外边界。以及还有注意力模块
步骤：原图-网络->虹膜掩膜、虹膜外边界和瞳孔掩膜->后处理操作估计参数化的虹膜内外边界，排除错误预测结果
特点：不依赖虹膜的情况下实现虹膜定位

### 
效果：

总结：方法三种：传统数学方法、基于像素直接方法，深度学习方法。
	传统数学：先定位（参数化内外边界）、后分割（排除睫毛等影响）
	基于像素：通过利用单个像素的低层次视觉信息，如强度和颜色，从图像背景中对感兴趣的像素进行分类
	深度学习：基于CNN




## 产品
| 公司名称      | 业务范畴                           | 业务场景                                 | 类型                         |
|---------------|------------------------------------|------------------------------------------|------------------------------|
| 掌虹科技      | 考勤，门禁，门锁，身份识别         | 校园，公司，停车场                       | 立柱，立柜，手持，挂壁，闸机 |
| 思源科安      | 虹膜开锁                           | 监狱，煤矿，司法矫正                     | 立式                         |
| 手机厂商      | 身份识别                           | 捕捉用户面部信息（含虹膜特征）           | 手机应用                     |
| 中科宏霸      | 考勤，身份认证，支付安全           | 公司，矿井，军事                         | 更衣柜，手持等               |
| 云飞励天      | 身份识别                           | 公安，人口失踪等                         | —                            |
| eyelook       | 身份认证                           | 电脑、邮箱登录                           | 虹膜扫描器                   |
还有医疗领域，检查身体情况，不过并没有找到合适的公司。


## Reference
1. https://blog.csdn.net/weixin_44230176/article/details/129860216	->IrisParseNet方法介绍
2. https://blog.csdn.net/zqx951102/article/details/107760893    	->DeepIrisNet2方法介绍
3. Iris Recognition: An Emerging Biometric Technology   		->Wildes方法介绍



