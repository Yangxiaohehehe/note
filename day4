# 任务情况
## 昨日进度
1. 了解了ONNX TFlite模型结构 
2. 实现了ONNX模型的拆分重组，以及打印每层信息输出情况

## 今日任务
1. 深入了解ONNX模型的内存分配情况，eg. 不同字节存放的是什么内容
2. 对TFLITE完成相关内容的了解
3. conventional如何运算



# ONNX
## 二进制文件结构
	Protobuf使用一种紧凑的二进制格式，每个字段都有特定的tag和类型，然后是数据
	ONNX模型由多个嵌套的Protobuf消息构成（见昨日笔记）
	要获取ONNX模型中每个节点（NodeProto）在原始文件中的内存地址（偏移量）和占用大小
	字段地址 = Tag字节 + Length字节 + Data字节
## 利用Python获得结论
	参数结构所占的模型大小占比百分之95以上
	元数据和结构占比较小
	见day3报告



# TFLITE
## 二进制文件结构
	明日

## operator
	onnx的操作是relu和conv分开，在TFlite中是放在一起的
	张量后的Type=3​（UINT8）和Type=9​（INT8）表示张量是量化后的
	重要的是**算子列表**：每一层的输入输出信息存储在 ​SubGraph中的Operators里，每个Operator对象中的inputs和outputs字段标号了张量的下标


# 卷积算计

## 基本的卷积运算
两者的卷积运算都支持相同的核心参数，包括卷积核大小（kernel size）、步长（stride）、填充（padding）、膨胀率（dilation）、分组数（groups）
1. 通过卷积核在输入数据（如图像）上按步长（stride）滑动，逐位置计算局部区域的加权和。
2. 输出特征图的每个值都是输入局部区域与卷积核的逐元素乘积之和（加上可选的偏置项）
3. 基本的参数有：卷积核尺寸，步长，padding，膨胀率，分组数
4. 卷积基本的填充方式:
		无填充：输出尺寸=⌊输入尺寸−卷积核尺寸+1​⌋/步长
		Same Padding（保持输出尺寸：输出尺寸=⌈输入尺寸/步长​⌉
		全填充：填充至卷积核能覆盖输入的所有可能位置，输出尺寸大于输入尺寸。 输出尺寸=『输入尺寸+卷积核尺寸−1​』/步长



## ONNX与TFlite卷积运算区别
| ​**分类**               | ​**TensorFlow Lite (TFLite)**                                                                 | ​**ONNX**                                                                                     | ​**注意事项**                                                                 |
|-------------------------|---------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| ​**填充计算方式**        | 支持 `SAME`（动态计算填充量）和 `VALID`（无填充）。                                           | 通过 `AutoPad` 属性指定：`SAME_UPPER`、`SAME_LOWER`、`VALID` 等。                           | 输入尺寸为奇数时，`SAME` 填充可能导致输出尺寸差异。                          |
| ​**数据格式**            | 默认使用 ​**NHWC**​（Batch, Height, Width, Channels）。                                       | 默认使用 ​**NCHW**​（Batch, Channels, Height, Width）。                                       | 模型转换时需显式处理格式转换（如通过转置操作）。                            |
| ​**激活函数融合**        | 支持与 ReLU、ReLU6 等激活函数融合为单一算子。                                                 | 激活函数通常为独立算子（如 `Relu`），依赖运行时优化实现融合。                               | 融合操作影响性能但不影响数学结果。                                          |
| ​**量化实现**            | 支持全整型量化（int8）、float16 等，依赖硬件加速器特性。                                      | 通过 `QuantizeLinear`/`DequantizeLinear` 算子实现量化，支持动态/静态量化。                   | 不同框架的量化参数（如零点、缩放因子）需对齐，否则结果不一致。              |
| ​**权重顺序**            | 卷积核权重形状为 `[H, W, InChannels, OutChannels]`（NHWC 格式）。                            | 卷积核权重形状为 `[OutChannels, InChannels, H, W]`（NCHW 格式）。                           | 转换模型时需转置权重顺序。                                                  |
| ​**膨胀卷积支持**        | 明确支持 `dilation` 参数，但部分旧版本移动端运行时可能有限制。                                | 通过 `dilations` 属性支持，需确保运行时支持。                                               | 验证目标设备/运行时的膨胀卷积兼容性。                                       |
| ​**分组卷积**            | 通过 `groups` 参数支持分组卷积（如深度可分离卷积）。                                          | 同样支持 `group` 参数，但需确保输入/输出通道数能被 `group` 整除。                           | 分组数不匹配会导致模型转换失败。                                            |
| ​**部署优化**            | 针对移动端/嵌入式设备优化，支持算子融合、内存重用等。                                          | 依赖运行时实现优化（如 ONNX Runtime 的图优化）。                                             | ONNX 的优化程度取决于具体运行时（如 ONNX Runtime vs. TensorRT）。          |
| ​**动态输入尺寸支持**    | 支持动态输入尺寸，但可能影响性能（需预分配内存）。                                             | 支持动态尺寸（通过 `None` 或符号维度），但部分运行时要求固定输入尺寸。                      | 部署前需测试目标平台对动态尺寸的支持。                                      |




