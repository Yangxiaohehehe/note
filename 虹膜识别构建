## 任务介绍
构建虹膜识别的框架
框架采用了掌识别的框架


## 数据集
数据集见虹膜调研部分

### 数据集前处理
数据集前处理方式：
从图片-> 图片+标注的形式
标注的产生由open-iris项目进行，得到了txt文件，形式为line：imgpath, LR, new_id，metadate, 虹膜坐标，瞳孔坐标（后两者为多边形）

并且进行了数据集的划分,0.8,0.2的比例划分.
同时需要注意,测试集和训练集**不能有重复的人出现**,同一个编号只能出现在一个集合当中.
  
  
### 数据集预处理
预处理为了适配掌识别的框架
主要是进行了line的分割，
---

        [['image', 'line'],                      'Line2PRLabelIris',         [],                              ['affined', "metadata", "cls", "lr"]],
        
---
从图片和line ->输出得到：涂黑后的图片+类别（即新id）+左右

输出metadata是方便改进使用，metadata具体是内部使用了眼部中心进行裁减。
裁减过程中有部分数据集存在眼部中心和iris_bbox不存在情况，使用了虹膜坐标推断平均值从而进行裁减.

左右的标签是因为在掌部分左右手比较像,所以加入了lr标签进行区分,在虹膜部分暂时不需要lr标签.

在预处理阶段，最后将图片resize成了256,256的形式，如需修改，在内部修改即可。

## 网络结构
整体网络结构沿用了掌识别部分
利用网络输出特征后进行arcface的损失进行区分


## 改进

### 1000_base
此版本是初步模型版本，利用了掌识别搭建框架。

可视化错误匹配
1. 针对涂黑，错误类型是形状，大多数遮挡后裁减的图片如果形状类似会被匹配错误    （open-iris归一化展开成为矩形的方法，极坐标归一化）
2. 不涂黑情况，错误率大幅度上升，一个图片会连着错好几幅图片。一小部分是图像质量原因，另一大部分问题是眼形的问题。


### 1001 极坐标映射
1001方法，采用了极坐标转换成256 256 矩形的方法,拟合成椭圆
1001方法：利用了极坐标展开为一个圆的方法。


可视化错误匹配：
1. 非常依赖属于预处理
2. 志麟哥指出：如果切分的位置不对，会导致识别率低

### 1002 全局特征
修改了网络结构，属于预处理沿用了1000的方法
网络结构采用了人脸识别部分的代码
利用了全局特征
并且缩小了迭代次数

效果来讲并不理想，依旧存在大量形状的问题


### 1005 数据增强 多mask融合
思路：
在先前存在了形状的问题

于是为了减少形状的影响，在数据预处理，除了本身就存在的mask，从其他图片的mask随机选择一个，这样形状就有所修改。

效果：
比1000base好







